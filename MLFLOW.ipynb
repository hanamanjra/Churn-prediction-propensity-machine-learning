{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9977b695",
   "metadata": {},
   "source": [
    "## MLFlow model \n",
    "\n",
    "In this code section we will cover how to create refractored code to automate the creation of numeroous models within mlflow. We will cover how to log your model, its parameters and metrics, and how to monitor this in MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3718b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Telco Churn Classification with CV and Model Logging...\n",
      "Data loaded. X_full shape: (7032, 20), y_full shape: (7032,)\n",
      "Preprocessor defined.\n",
      "\n",
      "--- Training Logistic Regression with Cross-Validation ---\n",
      "  Logistic Regression CV Results:\n",
      "    Mean Test accuracy: 0.8039 (Std: 0.0056)\n",
      "    Mean Test precision_weighted: 0.7959 (Std: 0.0056)\n",
      "    Mean Test recall_weighted: 0.8039 (Std: 0.0056)\n",
      "    Mean Test f1_weighted: 0.7982 (Std: 0.0053)\n",
      "    Mean Test ROC AUC: 0.8449 (Std: 0.0026)\n",
      "  Fitting final Logistic Regression pipeline on full training data for logging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/07/31 15:07:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c0f3859c2f44a796235b936d8cc563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/31 15:07:48 INFO mlflow.models.model: Found the following environment variables used during model inference: [OPENAI_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final Logistic Regression pipeline logged to: file:///c:/Users/hanam/OneDrive/repos/BA-MLOps/03%20Deploying%20%26%20Productionising%20ML%20Models/Example%20Exercises/mlruns/428641126348462805/ec33ffcbb3534082b702d12368190902/artifacts/final_model_pipeline\n",
      "\n",
      "--- Training Random Forest Classifier with Cross-Validation ---\n",
      "  Random Forest Classifier CV Results:\n",
      "    Mean Test accuracy: 0.7948 (Std: 0.0044)\n",
      "    Mean Test precision_weighted: 0.7820 (Std: 0.0050)\n",
      "    Mean Test recall_weighted: 0.7948 (Std: 0.0044)\n",
      "    Mean Test f1_weighted: 0.7817 (Std: 0.0037)\n",
      "    Mean Test ROC AUC: 0.8284 (Std: 0.0032)\n",
      "  Fitting final Random Forest Classifier pipeline on full training data for logging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/07/31 15:09:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe29efa17884f48b225eab3800226c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final Random Forest Classifier pipeline logged to: file:///c:/Users/hanam/OneDrive/repos/BA-MLOps/03%20Deploying%20%26%20Productionising%20ML%20Models/Example%20Exercises/mlruns/428641126348462805/d253d2f787b64790b8d9badf53184caa/artifacts/final_model_pipeline\n",
      "\n",
      "--- Training Gradient Boosting Classifier with Cross-Validation ---\n",
      "  Gradient Boosting Classifier CV Results:\n",
      "    Mean Test accuracy: 0.8039 (Std: 0.0065)\n",
      "    Mean Test precision_weighted: 0.7935 (Std: 0.0069)\n",
      "    Mean Test recall_weighted: 0.8039 (Std: 0.0065)\n",
      "    Mean Test f1_weighted: 0.7947 (Std: 0.0061)\n",
      "    Mean Test ROC AUC: 0.8473 (Std: 0.0047)\n",
      "  Fitting final Gradient Boosting Classifier pipeline on full training data for logging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanam\\AppData\\Roaming\\Python\\Python312\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/07/31 15:09:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8c0f02bec24200a1995ceb8a4b49d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final Gradient Boosting Classifier pipeline logged to: file:///c:/Users/hanam/OneDrive/repos/BA-MLOps/03%20Deploying%20%26%20Productionising%20ML%20Models/Example%20Exercises/mlruns/428641126348462805/852abb0705264e628c60a6fda4feb828/artifacts/final_model_pipeline\n",
      "\n",
      "All Telco Churn models processed with CV and models logged to MLflow.\n",
      "To view results, run 'mlflow ui' in your terminal and navigate to the 'Telco Churn Prediction CV & Model Logging' experiment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "# --- Constants ---\n",
    "N_SPLITS_CV = 5\n",
    "RANDOM_SEED = 42\n",
    "MLFLOW_EXPERIMENT_NAME = \"Telco Churn Prediction CV & Model Logging\"\n",
    "\n",
    "# --- Data Loading and Initial Preprocessing ---\n",
    "def load_data(data_path: str):\n",
    "    \"\"\"\n",
    "    Loads the Telco Customer Churn dataset, performs initial cleaning,\n",
    "    and separates features (X) from the target (y).\n",
    "    \"\"\"\n",
    "    churn = pd.read_csv(data_path)\n",
    "    churn['TotalCharges'] = pd.to_numeric(churn['TotalCharges'], errors='coerce')\n",
    "    churn.dropna(subset=['TotalCharges'], inplace=True)\n",
    "    \n",
    "    y = LabelEncoder().fit_transform(churn['Churn'])\n",
    "    X = churn.drop('Churn', axis=1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# --- Preprocessing Pipeline Definition ---\n",
    "def define_preprocessor(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Defines the preprocessing steps for numerical and categorical features.\n",
    "    \"\"\"\n",
    "    # Identify categorical and numerical features\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns\n",
    "\n",
    "    # Create preprocessing pipelines for numerical and categorical features\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Create a preprocessor using ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'  # Keep other columns not specified\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "# --- Model Training, Evaluation, and MLflow Logging Function ---\n",
    "def train_evaluate_log_model(model_name: str, classifier, X_full: pd.DataFrame, y_full: np.ndarray, model_params: dict, preprocessor: ColumnTransformer, n_splits_cv_param: int):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given model using cross-validation, logs metrics and the model to MLflow.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=f\"{model_name} Training\"):\n",
    "        print(f\"\\n--- Training {model_name} with Cross-Validation ---\")\n",
    "        mlflow.log_params(model_params)\n",
    "\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                   ('classifier', classifier(**model_params))])\n",
    "\n",
    "        cv_accuracies = []\n",
    "        cv_precisions = []\n",
    "        cv_recalls = []\n",
    "        cv_f1s = []\n",
    "        cv_roc_aucs = []\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_splits_cv_param, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X_full, y_full)):\n",
    "            X_train_fold, X_val_fold = X_full.iloc[train_index], X_full.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_full[train_index], y_full[val_index]\n",
    "\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = pipeline.predict(X_val_fold)\n",
    "            y_proba = pipeline.predict_proba(X_val_fold)[:, 1] if hasattr(pipeline, \"predict_proba\") else [0] * len(y_pred)\n",
    "\n",
    "            accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "            precision = precision_score(y_val_fold, y_pred, average='weighted', zero_division=0)\n",
    "            recall = recall_score(y_val_fold, y_pred, average='weighted')\n",
    "            f1 = f1_score(y_val_fold, y_pred, average='weighted')\n",
    "            roc_auc = roc_auc_score(y_val_fold, y_proba)\n",
    "\n",
    "            cv_accuracies.append(accuracy)\n",
    "            cv_precisions.append(precision)\n",
    "            cv_recalls.append(recall)\n",
    "            cv_f1s.append(f1)\n",
    "            cv_roc_aucs.append(roc_auc)\n",
    "\n",
    "            mlflow.log_metrics({\n",
    "                f\"fold_{fold+1}_accuracy\": accuracy,\n",
    "                f\"fold_{fold+1}_precision\": precision,\n",
    "                f\"fold_{fold+1}_recall\": recall,\n",
    "                f\"fold_{fold+1}_f1\": f1,\n",
    "                f\"fold_{fold+1}_roc_auc\": roc_auc\n",
    "            })\n",
    "\n",
    "        mean_accuracy = np.mean(cv_accuracies)\n",
    "        mean_precision = np.mean(cv_precisions)\n",
    "        mean_recall = np.mean(cv_recalls)\n",
    "        mean_f1 = np.mean(cv_f1s)\n",
    "        mean_roc_auc = np.mean(cv_roc_aucs)\n",
    "\n",
    "        print(f\"  {model_name} CV Results:\")\n",
    "        print(f\"    Mean Test accuracy: {mean_accuracy:.4f} (Std: {np.std(cv_accuracies):.4f})\")\n",
    "        print(f\"    Mean Test precision_weighted: {mean_precision:.4f} (Std: {np.std(cv_precisions):.4f})\")\n",
    "        print(f\"    Mean Test recall_weighted: {mean_recall:.4f} (Std: {np.std(cv_recalls):.4f})\")\n",
    "        print(f\"    Mean Test f1_weighted: {mean_f1:.4f} (Std: {np.std(cv_f1s):.4f})\")\n",
    "        print(f\"    Mean Test ROC AUC: {mean_roc_auc:.4f} (Std: {np.std(cv_roc_aucs):.4f})\")\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"mean_cv_accuracy\": mean_accuracy,\n",
    "            \"mean_cv_precision\": mean_precision,\n",
    "            \"mean_cv_recall\": mean_recall,\n",
    "            \"mean_cv_f1\": mean_f1,\n",
    "            \"mean_cv_roc_auc\": mean_roc_auc\n",
    "        })\n",
    "\n",
    "        print(f\"  Fitting final {model_name} pipeline on full training data for logging...\")\n",
    "        full_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                         ('classifier', classifier(**model_params))])\n",
    "        full_pipeline.fit(X_full, y_full)\n",
    "\n",
    "        # Infer signature for MLflow logging\n",
    "        example_input = X_full.sample(1, random_state=RANDOM_SEED)\n",
    "        signature = infer_signature(example_input, full_pipeline.predict(example_input))\n",
    "\n",
    "        # Log the final trained pipeline\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=full_pipeline, \n",
    "            artifact_path=\"final_model_pipeline\",\n",
    "            signature=signature,\n",
    "            input_example=example_input\n",
    "        )\n",
    "        print(f\"  Final {model_name} pipeline logged to: {mlflow.active_run().info.artifact_uri}/final_model_pipeline\")\n",
    "\n",
    "# --- Main Execution Function ---\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the entire ML pipeline: data loading, preprocessing,\n",
    "    and training/logging multiple models.\n",
    "    \"\"\"\n",
    "    print(\"Starting Telco Churn Classification with CV and Model Logging...\")\n",
    "\n",
    "    # Set MLflow experiment\n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "    # Load data\n",
    "    data_path = os.path.join(os.getcwd(), 'raw', 'WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    X_full, y_full = load_data(data_path)\n",
    "    print(f\"Data loaded. X_full shape: {X_full.shape}, y_full shape: {y_full.shape}\")\n",
    "\n",
    "    # Define preprocessor\n",
    "    preprocessor = define_preprocessor(X_full)\n",
    "    print(\"Preprocessor defined.\")\n",
    "\n",
    "    # Define models to compare\n",
    "    models_to_compare = [\n",
    "        {\n",
    "            \"name\": \"Logistic Regression\",\n",
    "            \"classifier\": LogisticRegression,\n",
    "            \"params\": {\"solver\": \"liblinear\", \"random_state\": RANDOM_SEED}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Random Forest Classifier\",\n",
    "            \"classifier\": RandomForestClassifier,\n",
    "            \"params\": {\"n_estimators\": 100, \"random_state\": RANDOM_SEED}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Gradient Boosting Classifier\",\n",
    "            \"classifier\": GradientBoostingClassifier,\n",
    "            \"params\": {\"n_estimators\": 100, \"random_state\": RANDOM_SEED}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Run the full pipeline for each model\n",
    "    for model_info in models_to_compare:\n",
    "        train_evaluate_log_model(\n",
    "            model_info[\"name\"],\n",
    "            model_info[\"classifier\"],\n",
    "            X_full,\n",
    "            y_full,\n",
    "            model_info[\"params\"],\n",
    "            preprocessor,  # Pass the preprocessor defined in main()\n",
    "            N_SPLITS_CV    # Pass the N_SPLITS_CV constant\n",
    "        )\n",
    "\n",
    "    print(\"\\nAll Telco Churn models processed with CV and models logged to MLflow.\")\n",
    "    print(f\"To view results, run 'mlflow ui' in your terminal and navigate to the '{MLFLOW_EXPERIMENT_NAME}' experiment.\")\n",
    "\n",
    "# --- Guard to run main() when script is executed directly ---\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89c03b",
   "metadata": {},
   "source": [
    "## Single and batch prediction locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8384bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow model loaded successfully from file///C:/Users/hanam/OneDrive/repos/BA-MLOps/03 Deploying & Productionising ML Models/Example Exercises/mlruns/428641126348462805/models/m-47434a991eb2402bae2a34fdbc097aee/artifacts\n",
      "\n",
      "--- Single Entry Prediction ---\n",
      "Prediction for single entry: {'prediction': 0}\n",
      "\n",
      "--- Batch Entry Prediction ---\n",
      "Predictions for batch entries: [{'prediction': 0}, {'prediction': 1}]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- Configuration ---\n",
    "# IMPORTANT: Replace this with the actual MLflow URI of your model\n",
    "# You can find this in the MLflow UI or the output of your logging cell\n",
    "# For example: \"runs:/<YOUR_RUN_ID>/final_model_pipeline\" or \"file:///path/to/your/mlruns/run_id/artifacts/final_model_pipeline\"\n",
    "MLFLOW_MODEL_URI = r\"file///C:/Users/hanam/OneDrive/repos/BA-MLOps/03 Deploying & Productionising ML Models/Example Exercises/mlruns/428641126348462805/models/m-47434a991eb2402bae2a34fdbc097aee/artifacts\"\n",
    "\n",
    "# --- Define Pydantic Model for Input Data ---\n",
    "# IMPORTANT: Adjust these features and types to precisely match your model's expected input\n",
    "# These are common features for a Telco Churn dataset.\n",
    "class TelcoChurnInput(BaseModel):\n",
    "    customerID: str\n",
    "    gender: str\n",
    "    SeniorCitizen: int\n",
    "    Partner: str\n",
    "    Dependents: str\n",
    "    tenure: int\n",
    "    PhoneService: str\n",
    "    MultipleLines: str\n",
    "    InternetService: str\n",
    "    OnlineSecurity: str\n",
    "    OnlineBackup: str\n",
    "    DeviceProtection: str\n",
    "    TechSupport: str\n",
    "    StreamingTV: str\n",
    "    StreamingMovies: str\n",
    "    Contract: str\n",
    "    PaperlessBilling: str\n",
    "    PaymentMethod: str\n",
    "    MonthlyCharges: float\n",
    "    TotalCharges: float\n",
    "\n",
    "# --- Load MLflow Model ---\n",
    "try:\n",
    "    loaded_model = mlflow.pyfunc.load_model(MLFLOW_MODEL_URI)\n",
    "    print(f\"MLflow model loaded successfully from {MLFLOW_MODEL_URI}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading MLflow model: {e}\")\n",
    "    loaded_model = None # Set to None to handle cases where model loading fails\n",
    "\n",
    "# --- Prediction Functions ---\n",
    "def predict_single_entry(data: TelcoChurnInput) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Performs prediction for a single customer entry.\n",
    "    \"\"\"\n",
    "    if loaded_model is None:\n",
    "        return {\"error\": \"Model not loaded. Cannot perform prediction.\"}\n",
    "\n",
    "    # Convert Pydantic model to a pandas DataFrame\n",
    "    input_df = pd.DataFrame([data.model_dump()]) # Changed .dict() to .model_dump()\n",
    "\n",
    "    # Handle 'TotalCharges' being potentially empty string\n",
    "    if 'TotalCharges' in input_df.columns:\n",
    "        input_df['TotalCharges'] = pd.to_numeric(input_df['TotalCharges'], errors='coerce')\n",
    "        input_df['TotalCharges'] = input_df['TotalCharges'].fillna(0) # Or another suitable imputation\n",
    "\n",
    "    predictions = loaded_model.predict(input_df)\n",
    "    # Assuming your model outputs a single prediction (e.g., 0 or 1)\n",
    "    # If your model outputs probabilities, adjust this.\n",
    "    prediction_result = predictions[0]\n",
    "\n",
    "    return {\"prediction\": int(prediction_result)} # Convert to int for JSON serialization\n",
    "\n",
    "def predict_batch_entry(data_list: List[TelcoChurnInput]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Performs batch predictions for multiple customer entries.\n",
    "    \"\"\"\n",
    "    if loaded_model is None:\n",
    "        return [{\"error\": \"Model not loaded. Cannot perform prediction.\"}]\n",
    "\n",
    "    # Convert list of Pydantic models to a pandas DataFrame\n",
    "    input_df = pd.DataFrame([data.model_dump() for data in data_list]) # Changed .dict() to .model_dump()\n",
    "\n",
    "    # Handle 'TotalCharges' being potentially empty string\n",
    "    if 'TotalCharges' in input_df.columns:\n",
    "        input_df['TotalCharges'] = pd.to_numeric(input_df['TotalCharges'], errors='coerce')\n",
    "        input_df['TotalCharges'] = input_df['TotalCharges'].fillna(0) # Or another suitable imputation\n",
    "\n",
    "    predictions = loaded_model.predict(input_df)\n",
    "\n",
    "    results = [{\"prediction\": int(pred)} for pred in predictions]\n",
    "    return results\n",
    "\n",
    "# --- Example Usage (within Jupyter Notebook) ---\n",
    "if __name__ == \"__main__\":\n",
    "    if loaded_model:\n",
    "        # Single entry example\n",
    "        single_customer_data = TelcoChurnInput(\n",
    "            customerID=\"1234-ABCD\", gender=\"Male\", SeniorCitizen=0, Partner=\"Yes\",\n",
    "            Dependents=\"No\", tenure=24, PhoneService=\"Yes\", MultipleLines=\"No\",\n",
    "            InternetService=\"Fiber optic\", OnlineSecurity=\"No\", OnlineBackup=\"Yes\",\n",
    "            DeviceProtection=\"No\", TechSupport=\"No\", StreamingTV=\"Yes\",\n",
    "            StreamingMovies=\"Yes\", Contract=\"Month-to-month\", PaperlessBilling=\"Yes\",\n",
    "            PaymentMethod=\"Electronic check\", MonthlyCharges=85.0, TotalCharges=2040.0\n",
    "        )\n",
    "        print(\"\\n--- Single Entry Prediction ---\")\n",
    "        single_prediction = predict_single_entry(single_customer_data)\n",
    "        print(f\"Prediction for single entry: {single_prediction}\")\n",
    "\n",
    "        # Batch entry example\n",
    "        batch_customers_data = [\n",
    "            TelcoChurnInput(\n",
    "                customerID=\"1234-ABCD\", gender=\"Male\", SeniorCitizen=0, Partner=\"Yes\",\n",
    "                Dependents=\"No\", tenure=24, PhoneService=\"Yes\", MultipleLines=\"No\",\n",
    "                InternetService=\"Fiber optic\", OnlineSecurity=\"No\", OnlineBackup=\"Yes\",\n",
    "                DeviceProtection=\"No\", TechSupport=\"No\", StreamingTV=\"Yes\",\n",
    "                StreamingMovies=\"Yes\", Contract=\"Month-to-month\", PaperlessBilling=\"Yes\",\n",
    "                PaymentMethod=\"Electronic check\", MonthlyCharges=85.0, TotalCharges=2040.0\n",
    "            ),\n",
    "            TelcoChurnInput(\n",
    "                customerID=\"5678-EFGH\", gender=\"Female\", SeniorCitizen=1, Partner=\"No\",\n",
    "                Dependents=\"No\", tenure=1, PhoneService=\"Yes\", MultipleLines=\"No\",\n",
    "                InternetService=\"DSL\", OnlineSecurity=\"No\", OnlineBackup=\"No\",\n",
    "                DeviceProtection=\"No\", TechSupport=\"No\", StreamingTV=\"No\",\n",
    "                StreamingMovies=\"No\", Contract=\"Month-to-month\", PaperlessBilling=\"No\",\n",
    "                PaymentMethod=\"Mailed check\", MonthlyCharges=29.85, TotalCharges=29.85\n",
    "            )\n",
    "        ]\n",
    "        print(\"\\n--- Batch Entry Prediction ---\")\n",
    "        batch_predictions = predict_batch_entry(batch_customers_data)\n",
    "        print(f\"Predictions for batch entries: {batch_predictions}\")\n",
    "    else:\n",
    "        print(\"Model was not loaded, cannot run examples.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
